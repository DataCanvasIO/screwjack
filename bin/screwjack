#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""A command line tool for manipulating docker modules.
"""

import click
import json
import os
import re
import sys
from collections import OrderedDict
from dateutil.parser import parse
from datetime import datetime
import time
import commands
from pytz import UTC
from ConfigParser import SafeConfigParser
import getpass
import requests
from itertools import chain
import subprocess


try:
    import screwjack
except:
    sys.path.append(os.path.join(os.path.dirname(__file__), "../"))
    import screwjack


# TODO:
#    1. handle Ctrl-C
#    2. create/release EMR cluster

class Cluster(object):
    def __init__(self, params):
        pass

    def create(self):
        pass

    def terminate(self):
        pass

    def save(self):
        pass

    def check(self):
        pass


param_type_map = {
    "string": "str",
    "integer": "int",
    "float": "float",
    "enum": "str",
    "file": "str",
    "cluster": "str",
    "map":"str"
}

def gettype(name):
    if name not in param_type_map:
        raise ValueError("Invalid type for %s" % name)
    name = param_type_map[name]
    t = getattr(__builtins__, name)
    if isinstance(t, type):
        return t
    raise ValueError(name)


def param_check(param_name, param_type):
    if param_type not in param_type_map.keys():
        raise ValueError("Invalid type for %s" % param_name)

    if not re.match("^[A-Za-z0-9_]+$", param_name):
        raise ValueError("Invalid Param name '%s'. Param type must be '[A-Za-z0-9_]*'" % param_name)


def inout_check(inout_name, inout_types, spec_json):
    if not re.match("^[A-Za-z0-9_]+$", inout_name):
        raise ValueError("Invalid Input/Output name '%s'. Input/Output name must '[A-Za-z0-9_]*'" % inout_name)

    if inout_name in spec_json['Input'].keys():
        raise ValueError("Input name '%s' already exist, please choose another one" % inout_name)

    if inout_name in spec_json['Output'].keys():
        raise ValueError("Output name '%s' already exist, please choose another one" % inout_name)

    for t in inout_types:
        if not re.match("^[a-z0-9\._]+$", t):
            raise ValueError("Invalid Input/Output type '%s'. Input/Output type must be '[a-z0-9\._]+$'." % t)


def safe_get_spec_json(ctx):
    if not ctx.obj.spec_json:
        print("Could not find 'spec.json' in current directory.")
        ctx.exit()
    return ctx.obj.spec_json


def check_docker_image(image_name):
    from subprocess import Popen, PIPE

    p = Popen('docker inspect -f "{{ .id }}" %s' % image_name,
              shell=True, stdout=PIPE, stderr=PIPE, close_fds=True)
    return p.wait() == 0


def get_working_root(io_params):
    common_path = os.path.commonprefix(map(os.path.realpath, io_params.values()))
    if os.path.isfile(common_path):
        return os.path.dirname(common_path)
    elif os.path.isdir(common_path):
        return common_path
    else:
        raise Exception("Invalid path type")


def map_to_dockerpath(io_params, docker_working_root="/zetdata"):
    if len(io_params) == 0:
        print("WARNING! None of Inputs or Outputs.")
        return "", ""

    working_root = get_working_root(io_params)
    if working_root in ['', '/']:
        print("WARNING! Please arrange your data into single directory.")

    working_volume_str = "-v %s:%s" % (working_root, docker_working_root)
    print(" ".join(["%s=%s" % (k, os.path.join(docker_working_root, os.path.relpath(v, working_root)))
                    for k, v in io_params.viewitems()]))
    return working_volume_str, " ".join(
        ["%s=%s" % (k, os.path.join(docker_working_root, os.path.relpath(v, working_root)))
         for k, v in io_params.viewitems()])


def print_spec_json(obj):
    print("Name         : %s(%s)" % (obj['Name'], obj['Version']))
    print("CategoryTags : %s" % obj['CategoryTags'])
    print("Params")
    for k, v in obj['Param'].items():
        print("  %s(%s) : '%s'" % (k, v['Type'], v['Default']))
    print("Inputs")
    for k, v in obj['Input'].items():
        print("  %s(%s)" % (k, ", ".join(v)))
    print("Outputs")
    for k, v in obj['Output'].items():
        print("  %s(%s)" % (k, ", ".join(v)))
    if "Meta" in obj:
        print("Meta")
        for k, v in obj['Meta'].items():
            print("  %s = %s" % (k, v))


def gen_dummy_global_param(username=None):
    if not username:
        username = getpass.getuser()
    return {
        "userName": {
            "Type": "string",
            "Val": username
        },
        "userId": {
            "Type": "string",
            "Val": "123"
        },
        "jobId": {
            "Type": "string",
            "Val": "456"
        },
        "blockId": {
            "Type": "string",
            "Val": "789"
        },
        "hue_server": {
            "Type": "string",
            "Val": "http://192.168.1.20:8888/"
        }
    }


class ZetModule(object):
    def __init__(self, username, module_home=None, keep_files=False, fast_build=True,
                 spec_server=None, dockermachine_env_name=None):
        self.spec_server = spec_server
        self.module_home = os.path.abspath(module_home or '.')
        self.username = username
        self.keep_files = keep_files
        self.fast_build = fast_build
        self.dockermachine_env_name = dockermachine_env_name
        if not self.dockermachine_env_name:
            self.dockermachine_env_name = "dev"
        sj_filename = os.path.join(module_home, "spec.json")
        if not os.path.isfile(sj_filename):
            self.spec_json = None
        else:
            with open(sj_filename, "r") as sj_in:
                self.spec_json = json.load(sj_in, object_pairs_hook=OrderedDict)

    @property
    def clusters_db(self):
        import yaml

        yaml_path = os.path.join(os.path.expanduser("~/.datacanvas.yml"))
        if not os.path.isfile(yaml_path):
            print "WARNING: Can not find '~/.datacanvas.yml'"
            return {}
        obj = yaml.load(open(yaml_path).read())
        # return {site['Host']: {c['Name']: {p['Name']: p for p in c['Parameters']}
        #                        for c in site['Clusters']}
        #         for site in obj}
        return {site['Host']: {c['Name']:c for c in site['Clusters']} for site in obj}

    @property
    def clusters(self):
        if self.spec_server:
            spec_server_host = self.spec_server.split(":")[0]
            return self.clusters_db.get(spec_server_host, None)


class DockerMachineAgent(object):

    def __init__(self, env_name):
        self.env_name = env_name

    def ls(self, workingdir):
        cmd_str = 'docker-machine ssh %s "ls %s"' % (self.env_name, workingdir)
        print cmd_str
        ret = subprocess.call(cmd_str, shell=True)
        return ret == 0

    def mkdir(self, workingdir):
        cmd_str = 'docker-machine ssh %s "mkdir -p %s"' % (self.env_name, workingdir)
        print cmd_str
        ret = subprocess.call(cmd_str, shell=True)
        return ret == 0

    def rm(self, workingdir):
        cmd_str = 'docker-machine ssh %s "rm -rf %s"' % (self.env_name, workingdir)
        print cmd_str
        ret = subprocess.call(cmd_str, shell=True)
        return ret == 0

    def cleanup_dir(self, workingdir):
        return self.rm(workingdir) and self.mkdir(workingdir)

    def get_pwd(self):
        cmd_str = 'docker-machine ssh %s "pwd"' % self.env_name
        print cmd_str
        p = subprocess.Popen(cmd_str, shell=True,
                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        out, err = p.communicate()
        if p.returncode == 0:
            return out.strip()
        else:
            return None

    def deploy_files(self, filenames, remote_path):
        p1_cmd = ["tar", "-zcf", "-"] + filenames
        p2_cmd = ["docker-machine", "ssh", self.env_name, "tar -C %s -zxf -" % remote_path]
        print "%s | %s" % (" ".join(p1_cmd), " ".join(p2_cmd))
        p1 = subprocess.Popen(p1_cmd, stdout=subprocess.PIPE)
        p2 = subprocess.Popen(p2_cmd, stdin=p1.stdout, stdout=subprocess.PIPE)
        out, err = p2.communicate()
        # TODO : return p1.returncode == 0 and p2.returncode == 0
        return p2.returncode == 0




base_images = ['zetdata/ubuntu:trusty', 'zetdata/ubuntu:14.04',
               'zetdata/ubuntu:saucy', 'zetdata/ubuntu:13.10',
               'zetdata/ubuntu:raring', 'zetdata/ubuntu:13.04',
               'zetdata/ubuntu:precise', 'zetdata/ubuntu:12.04',
               'zetdata/ubuntu:lucid', 'zetdata/ubuntu:10.4',
               'zetdata/sci-python:2.7',
               'zetdata/cdh:4', 'zetdata/cdh:new',
               'zetdata/r:3.0.2']

param_types = ['integer', 'enum', 'float', 'string', 'file']


def gen_base_image_option(module_type):
    if module_type in ['basic','spark']:
        default_base_image = "zetdata/ubuntu:trusty"
    elif module_type == 'hive':
        default_base_image = "zetdata/cdh:new"
    elif module_type == 'pig':
        default_base_image = "zetdata/cdh:new"
    elif module_type in ['emr_hive', 'emr_jar']:
        default_base_image = "zetdata/cdh:new"
    elif module_type in ['r']:
        default_base_image = "zetdata/r:3.0.2"
    else:
        default_base_image = "zetdata/ubuntu:trusty"

    return click.Option(('--base-image', '-b'), prompt="Base Image",
                        type=click.Choice(base_images),
                        default=default_base_image,
                        help="Base Image")


def get_default_entry_cmd(module_type):
    if module_type in ['r']:
        return "Rscript main.R"
    else:
        return "python main.py"


@click.group()
@click.option('--username', envvar='DATACANVAS_USERNAME', required=True)
@click.option('--module-home', envvar="DATACANVAS_MODULE_HOME", default=".")
@click.option('--keep-files/--no-keep-files', envvar='DATACANVAS_KEEP_FILES', default=False)
@click.option('--fast-build/--full-build', envvar='DATACANVAS_KEEP_FILES', default=True)
@click.option('--spec_server', envvar='DATACANVAS_SPEC_SERVER', required=False)
@click.option('--dockermachine_env_name', envvar='DATACANVAS_DM_ENV', required=False)
@click.pass_context
def cli(ctx, username, module_home, keep_files, fast_build, spec_server, dockermachine_env_name):
    ctx.obj = ZetModule(username, module_home, keep_files, fast_build, spec_server, dockermachine_env_name)


@cli.command(short_help="Show version of Screwjack")
@click.pass_context
def version(ctx):
    import screwjack

    click.echo('Version %s' % screwjack.__version__)
    ctx.exit()


class InitCLI(click.MultiCommand):
    def list_commands(self, ctx):
        rv = ['basic', 'hive', 'pig', 'emr_hive', 'emr_pig', 'emr_jar', 'r','spark']
        return rv

    def get_command(self, ctx, module_type):

        @click.pass_context
        def init_callback(ctx, name, description, version, cmd, base_image):
            print("init %s" % module_type)
            obj = OrderedDict()
            obj['Name'] = name
            obj['Description'] = description
            obj['Version'] = version
            obj['Cmd'] = cmd
            obj['Param'] = {}
            obj['Input'] = {}
            obj['Output'] = {}
            obj['BaseImage'] = base_image

            target_path = obj['Name'].lower()
            if os.path.exists(target_path):
                print("Path %s exist, can not create" % target_path)
                exit(-1)

            # Generate files
            os.makedirs(target_path)

            from jinja2 import Environment, PackageLoader

            env = Environment(loader=PackageLoader('screwjack', 'templates/%s' % module_type))

            for tmpl_file in env.list_templates():
                target_file = os.path.splitext(tmpl_file)[0]
                tmpl = env.get_template(tmpl_file)
                with open(os.path.join(target_path, target_file), "w") as f:
                    f.write(tmpl.render(obj))

            # TODO:
            if module_type in ['hive', 'emr_hive']:
                os.makedirs(os.path.join(target_path, "resources/files"))
                os.makedirs(os.path.join(target_path, "resources/udfs"))
            if module_type in ['pig', 'emr_pig']:
                os.makedirs(os.path.join(target_path, "resources/udfs"))

            # Show Info
            print("Successfully created '%s'" % target_path)

        params = [
            click.Option(('--name', '-n'), prompt="Module Name", required=True,
                         help="Module Name"),
            click.Option(('--description', '-d'), prompt="Module Description", required=True,
                         help="Module Description"),
            click.Option(('--version', '-v'), prompt="Module Version",
                         default="0.1",
                         help="Module Version"),
            click.Option(('--cmd', '-c'), prompt="Module Entry Command",
                         default=get_default_entry_cmd(module_type),
                         help="Entry Command"),
            gen_base_image_option(module_type)
        ]

        return click.Command(module_type, help="Create a '%s' type of module" % module_type,
                             params=params, callback=init_callback)


@cli.command(cls=InitCLI, short_help="Run module in local/docker mode")
@click.pass_context
def init(ctx, *args, **kvargs):
    pass


@cli.command(short_help="Add a 'Param' to 'spec.json'")
@click.argument('param_key', nargs=1)
@click.argument('param_type', nargs=1, required=True)
@click.pass_context
def param_add(ctx, param_key, param_type):
    data = safe_get_spec_json(ctx)
    param_check(param_key, param_type)

    data['Param'][param_key] = {'Default': '', 'Type': param_type}
    with open("spec.json", "w") as sj_out:
        sj_out.write(json.dumps(data, indent=4, separators=(',', ': ')))
    print_spec_json(data)


@cli.command(short_help="Remove a 'Param' from 'spec.json'")
@click.argument('param_key', nargs=1)
@click.pass_context
def param_del(ctx, param_key):
    data = safe_get_spec_json(ctx)
    data['Param'].pop(param_key, 0)

    with open("spec.json", "w") as sj_out:
        sj_out.write(json.dumps(data, indent=4, separators=(',', ': ')))
    print_spec_json(data)


@cli.command(short_help="Add a 'Input' parameter to 'spec.json'")
@click.option('--expand-type/--no-expand-type', required=False, default=False)
@click.argument('input_name', nargs=1)
@click.argument('input_types', nargs=-1, required=True)
@click.pass_context
def input_add(ctx, expand_type, input_name, input_types):
    data = safe_get_spec_json(ctx)
    inout_check(input_name, input_types, data)

    if expand_type:
        input_types = list(input_types) + \
                      list(chain.from_iterable([expand_parent_type(t) for t in input_types]))
    else:
        input_types = list(input_types)

    data['Input'][input_name] = list(input_types)
    with open("spec.json", "w") as sj_out:
        sj_out.write(json.dumps(data, indent=4, separators=(',', ': ')))
    print_spec_json(data)


@cli.command(short_help="Remove a 'Input' parameter from 'spec.json'")
@click.argument('input_key', nargs=1)
@click.pass_context
def input_del(ctx, input_key):
    data = safe_get_spec_json(ctx)
    data['Input'].pop(input_key, 0)

    with open("spec.json", "w") as sj_out:
        sj_out.write(json.dumps(data, indent=4, separators=(',', ': ')))
    print_spec_json(data)


@cli.command(short_help="Add a 'Output' parameter to 'spec.json'.")
@click.option('--expand-type/--no-expand-type', required=False, default=True)
@click.argument('output_name', nargs=1)
@click.argument('output_types', nargs=-1, required=True)
@click.pass_context
def output_add(ctx, expand_type, output_name, output_types):
    data = safe_get_spec_json(ctx)
    inout_check(output_name, output_types, data)

    if expand_type:
        output_types = list(output_types) + \
                       list(chain.from_iterable([expand_parent_type(t) for t in output_types]))
    else:
        output_types = list(output_types)

    data['Output'][output_name] = list(output_types)
    with open("spec.json", "w") as sj_out:
        sj_out.write(json.dumps(data, indent=4, separators=(',', ': ')))
    print_spec_json(data)


@cli.command(short_help="Remove a 'Output' parameter from 'spec.json'.")
@click.argument('output_key', nargs=1)
@click.pass_context
def output_del(ctx, output_key):
    data = safe_get_spec_json(ctx)
    data['Output'].pop(output_key, 0)

    with open("spec.json", "w") as sj_out:
        sj_out.write(json.dumps(data, indent=4, separators=(',', ': ')))
    print_spec_json(data)


@cli.command(short_help="Package current module into a tar file.")
@click.pass_context
def package(ctx):
    internal_package()


@cli.command(short_help="Login to spec_server")
@click.option('--password', prompt=True, hide_input=True)
@click.pass_context
def login(ctx, password):
    if not ctx.obj.username:
        click.echo("Please input username")
        ctx.exit()
    if not ctx.obj.spec_server:
        click.echo("Please input spec_server")
        ctx.exit()

    click.echo("Logining into spec_server:'%s'" % ctx.obj.spec_server)

    cfg = SafeConfigParser()
    cfg.read(os.path.expanduser("~/.screwjack.cfg"))
    if not cfg.has_section('user'):
        cfg.add_section('user')
    cfg.set('user', 'username', ctx.obj.username)
    cfg.set('user', 'spec_server', ctx.obj.spec_server)
    cfg.write(open(os.path.expanduser("~/.screwjack.cfg"), "w"))

    # login into spec_server
    spec_server_url = "http://%s/register" % ctx.obj.spec_server
    spec_server_payload = {"user": ctx.obj.username, "passwd": password}
    r = requests.post(spec_server_url, data=json.dumps(spec_server_payload),
                      headers={'Content-type': 'application/json'})
    if r.status_code == 200:
        cfg.set('user', 'spec_auth', r.json()['token'])
        cfg.write(open(os.path.expanduser("~/.screwjack.cfg"), "w"))
    else:
        click.echo("Failed to login into server:")
        print(r.text)


templateType_map = OrderedDict([
    ("none", 0),
    ("hive", 1),
    ("pig", 2),
    ("emr_hive", 3),
    ("emr_pig", 4)])


def internal_submit(spec_push_url, ctx, templateType, is_private=False):
    """
    A internal function to submit/import module to spec_server.
    """

    sj = safe_get_spec_json(ctx)
    filename = "%s-%s.tar" % (sj['Name'].lower(), sj['Version'])
    if not os.path.exists(filename):
        internal_package()

    spec_push_params = {
        "user": ctx.obj.username,
        "templateType": templateType_map[templateType],
        "private": is_private
    }

    cfg = SafeConfigParser()
    cfg.read(os.path.expanduser("~/.screwjack.cfg"))

    r = requests.post(spec_push_url,
                      files={'moduletar': open(filename, "rb")},
                      headers={'x-spec-auth': cfg.get('user', 'spec_auth')},
                      params=spec_push_params)

    if r.status_code != 200:
        print("ERROR : Failed to submit")
        print(r.text)
        print(r.url)
        sys.exit(-1)
    else:
        print(r.text)
        if not async_wait_submit(ctx, r.json()["id"]):
            print("ERROR : Failed to submit module %s" % filename)
            sys.exit(-2)
        else:
            print("Successful submit module %s" % filename)
            sys.exit(0)


@cli.command(short_help="Submit current module to spec_server.")
@click.option("--templateType", type=click.Choice(templateType_map.keys()), default='none')
@click.option('--private/--public', envvar='DATACANVAS_KEEP_FILES', default=False)
@click.pass_context
def submit(ctx, templateType, private):
    print "Submitting to spec_server : '%s' ..." % ctx.obj.spec_server
    spec_push_url = "http://%s/spec/push" % ctx.obj.spec_server
    internal_submit(spec_push_url, ctx, templateType, private)


@cli.command(short_help="Import current module to spec_server.")
@click.option("--templateType", type=click.Choice(templateType_map.keys()), default='none')
@click.pass_context
def submit_import(ctx, templateType):
    print "Importing to spec_server : '%s' ..." % ctx.obj.spec_server
    spec_push_url = "http://%s/spec/import" % ctx.obj.spec_server
    internal_submit(spec_push_url, ctx, templateType)


def build_zetrt_params(ctx, param_kvs):
    spec_json = safe_get_spec_json(ctx)

    clusters = ctx.obj.clusters

    def build_val(p, v):
        import copy
        p = copy.deepcopy(p)
        if p["Type"] in ["cluster"]:
            if not v in clusters:
                print "Can not find cluster '%s' from ~/.datacanvas.yml" % v
                ctx.exit(1)

            p.update(Val=json.dumps(clusters[v]))
            return p
        else:
            p.update(Val=v)
            return p

    ret = {k: build_val(spec_json["Param"][k], v) for k, v in param_kvs.items()}
    print ret
    return ret


class RunCLI(click.MultiCommand):

    def list_commands(self, ctx):
        rv = ['local', 'docker', 'docker-machine']
        rv.sort()
        return rv

    def get_command(self, ctx, name):
        spec_json = safe_get_spec_json(ctx)

        ns = {}
        params = []

        for k, v in spec_json['Param'].iteritems():
            params.append(click.Option(("--param-%s" % k, ), prompt="Param '%s'" % k, default=v['Default'],
                                       type=gettype(v['Type']), help="Param(%s)" % v['Type']))
        for k, v in spec_json['Input'].iteritems():
            params.append(click.Option(("--%s" % k, ), prompt="Input '%s'" % k, help="Input"))
        for k, v in spec_json['Output'].iteritems():
            params.append(click.Option(("--%s" % k, ), prompt="Output '%s'" % k, help="Output"))

        def build_zetrt(ctx, kwargs, zetrt_dir="."):
            # TODO: support 'cluster' type
            params_kv = {re.sub(r'^param_(.*)', r'\1', k): v
                         for k, v in kwargs.viewitems()
                         if re.match(r'^param_(.*)', k)}

            obj = {"PARAM": build_zetrt_params(ctx, params_kv), "GLOBAL_PARAM": gen_dummy_global_param()}
            import tempfile

            zetrt_file = tempfile.NamedTemporaryFile(mode="w+", suffix=".json",
                                                     prefix="./zetrt_tmp_",
                                                     dir=zetrt_dir, delete=False)
            zetrt_file.write(json.dumps(obj, indent=4, separators=(',', ': ')))
            zetrt_file.close()
            return zetrt_file

        @click.pass_context
        def run_callback(ctx, *args, **kwargs):
            spec_json = safe_get_spec_json(ctx)

            # split params into two groups
            io_params = {k: v for k, v in kwargs.viewitems() if not re.match(r'^param_(.*)', k)}
            io_params_str = " ".join(["%s=%s" % (k, v) for k, v in io_params.viewitems()])
            zetrt_file = build_zetrt(ctx, kwargs)

            # Build command to execute
            print("Running in local...")
            cmd = "ZETRT=%s %s %s" % (zetrt_file.name, spec_json['Cmd'], io_params_str)
            print("Executing : '%s'" % cmd)
            ret = os.system(cmd)
            if not ctx.obj.keep_files:
                os.remove(zetrt_file.name)
            sys.exit(ret)

        @click.pass_context
        def docker_callback(ctx, *args, **kwargs):
            internal_build(ctx, False)
            spec_json = safe_get_spec_json(ctx)

            # split params into two groups
            io_params = {k: v for k, v in kwargs.viewitems() if not re.match(r'^param_(.*)', k)}
            io_vol_str, io_params_str = map_to_dockerpath(io_params)
            zetrt_file = build_zetrt(ctx, kwargs)
            zetrt_docker_filename = os.path.join("/home/work/", os.path.relpath(zetrt_file.name))
            module_path = "%s/%s" % (ctx.obj.username, spec_json['Name'].lower())

            if not check_docker_image(module_path):
                print("ERROR : Can not find image, ")
                print("        please use 'docker build -t %s .'" % module_path)
                print("        to build your image first.")
                ctx.exit()
            else:
                print("Module '%s' found" % module_path)

            # Build command to execute
            print("Running in docker...")
            cur_dir = os.path.realpath(os.path.curdir)
            cmd = "docker run -i -v %s:/home/work/ %s -w=/home/run -e ZETRT=%s -t %s %s %s" % (
                cur_dir, io_vol_str, zetrt_docker_filename, module_path, spec_json['Cmd'], io_params_str)
            print("Executing : '%s'" % cmd)

            ret = os.system(cmd)
            if not ctx.obj.keep_files:
                os.remove(zetrt_file.name)
            sys.exit(ret)

        @click.pass_context
        def dockermachine_callback(ctx, *args, **kwargs):
            internal_build(ctx, False)
            spec_json = safe_get_spec_json(ctx)

            # split params into two groups
            io_params = {k: v for k, v in kwargs.viewitems() if not re.match(r'^param_(.*)', k)}
            io_vol_str, io_params_str = map_to_dockerpath(io_params)
            zetrt_file = build_zetrt(ctx, kwargs)
            zetrt_docker_filename = os.path.join("/home/work/", os.path.relpath(zetrt_file.name))
            module_path = "%s/%s" % (ctx.obj.username, spec_json['Name'].lower())

            if not check_docker_image(module_path):
                print("ERROR : Can not find image, ")
                print("        please use 'docker build -t %s .'" % module_path)
                print("        to build your image first.")
                ctx.exit()
            else:
                print("Module '%s' found" % module_path)

            # Build command to execute
            print("Running in docker-machine...")
            dm = DockerMachineAgent(env_name=ctx.obj.dockermachine_env_name)
            remote_home = dm.get_pwd()
            if not remote_home:
                print "Invalid home path : %s" % remote_home
                sys.exit(-1)
            if dm.cleanup_dir(os.path.join(remote_home, "work")):
                # local_filename = os.path.basename(zetrt_file.name)
                root, dirs, local_filenames = next(os.walk("."))
                remote_filename = os.path.join(remote_home, "work")
                if not dm.deploy_files(local_filenames, remote_filename):
                    raise Exception("Failed to deploy local file to remote docker machine")

            # TODO: Overwrite volume mapping path
            io_vol_str = "-v %s:/zetdata" % os.path.join(remote_home, "work")
            cur_dir = os.path.join(remote_home, "work")

            cmd = "eval $(docker-machine env %s); docker run -i -v %s:/home/work/ %s -w=/home/run -e ZETRT=%s -t %s %s %s" % (
                dm.env_name,
                cur_dir, io_vol_str, zetrt_docker_filename, module_path, spec_json['Cmd'], io_params_str)
            print("Executing : '%s'" % cmd)

            ret = os.system(cmd)
            if not ctx.obj.keep_files:
                os.remove(zetrt_file.name)
            sys.exit(ret)

        if name == "local":
            return click.Command(name, params=params, callback=run_callback)
        elif name == "docker":
            return click.Command(name, params=params, callback=docker_callback)
        elif name == "docker-machine":
            return click.Command(name, params=params, callback=dockermachine_callback)
        else:
            return None


@cli.command(short_help="Print summary of 'spec.json'")
@click.pass_context
def show(ctx):
    data = safe_get_spec_json(ctx)
    print_spec_json(data)


@cli.command(short_help="Render current 'spec.json' to a graphviz file")
def draw():
    with open("spec.json", "r") as jf:
        spec_json = json.load(jf)
    from jinja2 import Environment, PackageLoader

    jinja2_env = Environment(loader=PackageLoader('screwjack', 'misc_templates'))
    template = jinja2_env.get_template("draw_spec_json.dot.j2")
    print(template.render(spec_json))


@cli.command(short_help="Build current image")
@click.option('--force', is_flag=True, default=False, help='force to rebuild')
@click.pass_context
def build(ctx, force):
    internal_build(ctx, force)


def internal_build(ctx, force):
    spec_json = safe_get_spec_json(ctx)
    module_path = "%s/%s" % (ctx.obj.username, spec_json['Name'].lower())

    def _build():
        if ctx.obj.fast_build:
            build_cmd = 'docker build -t %s .' % module_path
        else:
            build_cmd = 'docker build --no-cache=true -t %s .' % module_path
        print("Executing: %s" % build_cmd)
        if os.system(build_cmd) != 0:
            print("Failed to build '%s'" % module_path)
            sys.exit(-1)

    img_date_str = commands.getoutput('docker inspect -f "{{ .created }}" %s' % module_path)
    print(img_date_str)
    try:
        img_date = parse(img_date_str)
    except Exception as e:
        # No such image
        print("Image '%s' not found, force to rebuild" % module_path)
        _build()
        return

    if force:
        _build()
        return
    modified_files = list(files_in_images(img_date))
    if len(modified_files) > 0:
        print("The following files are modified(against image: '%s'):" % module_path)
        for fn in modified_files:
            print(fn)
        if query_yes_no("Rebuild?"):
            print("Building")
            _build()
    else:
        print("No need for rebuilding.")


dsTypeMap = OrderedDict([
    ("local_file", "LocalFile"),
    ("http", "Http"),
    ("ftp", "Ftp"),
    ("s3", "AWS_S3"),
    ("hdfs", "HDFS"),
    ("hive", "HIVE")])


@cli.command(short_help="generate a datasource")
@click.option("--ds_type", type=click.Choice(dsTypeMap.keys()),
              default='http', required=True)
@click.option("--ds_name", default='', required=True)
@click.option("--ds_url", default='', required=True)
@click.argument('meta_kvs', nargs=-1, required=False)
@click.pass_context
def gen_ds(ctx, ds_type, ds_name, ds_url, meta_kvs):
    metas = {k: v for k, v in [i.split("=") for i in meta_kvs]}
    ds = OrderedDict()
    ds["Name"] = ds_name
    ds["Type"] = dsTypeMap[ds_type]
    ds["URL"] = ds_url
    ds["Meta"] = metas
    print json.dumps(ds, indent=4, separators=(',', ': '))


@cli.command(short_help="increase a version")
@click.pass_context
def incr_ver(ctx):
    data = safe_get_spec_json(ctx)
    ver = data["Version"].split(".")
    ver[-1] = str(int(ver[-1]) + 1)
    data["Version"] = ".".join(ver)

    with open("spec.json", "w") as sj_out:
        sj_out.write(json.dumps(data, indent=4, separators=(',', ': ')))
    print_spec_json(data)


meta_defaults = {"isDeterministic": "true"}


@cli.command(short_help="set meta")
@click.argument('meta_key', nargs=1, type=click.Choice(meta_defaults.keys()))
@click.argument('meta_val', nargs=-1, required=False)
@click.pass_context
def meta_set(ctx, meta_key, meta_val):
    print meta_key
    print meta_val
    data = safe_get_spec_json(ctx)
    data["Meta"] = data.get("Meta", {})
    if len(meta_val) > 0:
        data["Meta"][meta_key] = meta_val[0]
    else:
        data["Meta"][meta_key] = meta_defaults.get(meta_key, "")

    with open("spec.json", "w") as sj_out:
        sj_out.write(json.dumps(data, indent=4, separators=(',', ': ')))
    print_spec_json(data)


@cli.command(short_help="new clusters")
@click.pass_context
def new_cluster(ctx):
    pass


@cli.command(short_help="list clusters")
@click.pass_context
def list_clusters(ctx):
    pass


@cli.command(short_help="fetch clusters from datacanvas")
@click.pass_context
def fetch_clusters(ctx):
    pass


@cli.command(short_help="publish clusters")
@click.pass_context
def push_clusters(ctx):
    pass


@cli.command(cls=RunCLI, short_help="Run module in local/docker mode")
@click.pass_context
def run(ctx, *args, **kvargs):
    pass


def internal_package():
    import re

    files = [i[0][0] for i in [re.findall(r'^ADD (.*) (.*)$', line)
                               for line in open("Dockerfile")]
             if len(i) > 0]
    files.append("Dockerfile")

    with open("spec.json", "r") as sj:
        sj = json.load(sj, object_pairs_hook=OrderedDict)
    filename = "%s-%s.tar" % (sj['Name'].lower(), sj['Version'])

    print("Packaging files: %s into '%s'" % (files, filename))
    import tarfile

    with tarfile.open(filename, "w") as tar:
        for name in files:
            tar.add(name)


def files_in_images(img_date):
    for root, dirs, files in os.walk("."):
        for fn in files:
            p = os.path.join(root, fn)
            file_mtime = UTC.localize(datetime.fromtimestamp(os.path.getmtime(p)))
            if img_date < file_mtime:
                # print("%s : %s" % (img_date, file_mtime))
                yield p


def query_yes_no(question, default="yes"):
    """Ask a yes/no question via raw_input() and return their answer.

    "question" is a string that is presented to the user.
    "default" is the presumed answer if the user just hits <Enter>.
        It must be "yes" (the default), "no" or None (meaning
        an answer is required of the user).

    The "answer" return value is one of "yes" or "no".
    """
    valid = {"yes": True, "y": True, "ye": True,
             "no": False, "n": False}
    if default == None:
        prompt = " [y/n] "
    elif default == "yes":
        prompt = " [Y/n] "
    elif default == "no":
        prompt = " [y/N] "
    else:
        raise ValueError("invalid default answer: '%s'" % default)

    while True:
        sys.stdout.write(question + prompt)
        choice = raw_input().lower()
        if default is not None and choice == '':
            return valid[default]
        elif choice in valid:
            return valid[choice]
        else:
            sys.stdout.write("Please respond with 'yes' or 'no' " \
                             "(or 'y' or 'n').\n")


def async_wait_submit(ctx, job_id):
    print("Waiting :'%s'" % job_id)
    while True:
        time.sleep(1)
        spec_status_url = "http://%s/status" % ctx.obj.spec_server

        r = requests.get(spec_status_url,
                         params={"id": job_id},
                         headers={'x-spec-auth': cfg.get('user', 'spec_auth')})
        rj = r.json()
        if rj['status'] == 'success':
            return True
        elif rj['status'] == 'pending':
            print ".",
            continue
        elif rj['status'] == 'failed':
            print("Failed to build : '%s'" % rj['message'])
            return False
        else:
            print("Unknow status : '%s'" % rj['status'])
            return False


def expand_parent_type(src_type):
    tmp_src_type = src_type.split(".")
    len_of_src_type = len(tmp_src_type)
    return [".".join(tmp_src_type[:-i]) for i in range(1, len_of_src_type)]


def pprint_json(obj):
    return json.dumps(obj, sort_keys=True, indent=4, separators=(',', ': '))


if __name__ == "__main__":
    if 'DATACANVAS_USERNAME' in os.environ:
        cli(default_map={'username': os.environ['DATACANVAS_USERNAME']})
    else:
        cfg = SafeConfigParser()
        cfg.read(os.path.expanduser("~/.screwjack.cfg"))
        default_map = {}
        if cfg.has_section('user') and cfg.has_option('user', 'username'):
            default_map['username'] = cfg.get('user', 'username')
        if cfg.has_section('user') and cfg.has_option('user', 'spec_server'):
            default_map['spec_server'] = cfg.get('user', 'spec_server')

        if default_map:
            cli(default_map=default_map)
        else:
            cli()
